 2016因为一场人机博弈让人们重新审视人工智能。AlphaGo击败李世乭一时间引起了众多媒体的关注，尽管已经过去一段时间。而人工智能、机器学习和深度学习这些词已然成为媒体热词，一时人工智能之风席卷全球。 那么什么是人工智能，什么是AL，什么又是深度学习呢？﻿﻿

图片发自简书App
﻿

在探讨人工智能之前，首先了解这几个概念。 机器学习不等于人工智能，机器学习只是人工智能实现的一种方法。机器学习区别于深度学习在于，内向的属于机器学习，最内的属于深度学习，其中的差异下面将会简要阐述。

有关人工智能：（注意一个反复强调的数据）

1.过去二十年，在大数据集的数字化、建立管理大数据集的基础框架和大数据计算范式上的进展，是解释本世纪先后将重点放在数据科学和人工智能上的主要原因。

2.一旦我们数字化了数据，使得他们可以被程序处理，下一步就是撬动自动化和对未来的预测。随着预测能力的增加，似乎更多“智能”的方面展现了出 来。于是我们将“数据科学”这样的术语改为“人工智能”。事实上这二者之间并没有什么明显的差别，只是感觉上的新奇和困难程度不同而已。新奇度和难度随着 时间是呈正态分布。今天“人工智能”给人的感觉就和昨天的“数据科学”一样。

3.从数据中学习的AI叫做机器学习。传统的机器学习从原始数据中提取人们可以识别的特征，然后通过学习这些特征产生一个最终的模型。现在大多是利用神经网络控制算法实现简单的人工智能。

有关机器学习：

1、机器学习最根本的点在于使用算法来分析数据的实践、学习，然后对真实的事件作出决定或预测。而不是用一组特定的指令生成的硬编码软件程序来解决特定任务，机器是通过使用大量的数据和算法来训练，这样就给了它学习如何执行任务的能力。

2、机器学习是早期人工智能人群思考的产物，多年来形成的算法包括决策树学习、归纳逻辑编程、聚类、强化学习、贝叶斯网络等等。正如我们所知，所有这些都没有实现强人工智能的最终目标，而早期的机器学习方法甚至连弱人工智能都没有触及到。

3、事实证明，多年来机器学习的最佳应用领域之一是计算机视觉，尽管仍然需要大量的手工编码来完成这项工作。人们会去写手工编码分类器，如边缘检测滤波器，以便程序可以识别一个目标的启动和停止；进行形状检测以确定它是否有八个侧面；同时确保分类器能 够识别字母「s-t-o-p.」从那些手工编码分类器中，机器就会开发算法使得图像和「学习」更有意义，用来确定这是否是一个停止标志。 结果还算不错，但这还不够。特别是在雾天当标志不那么清晰，或有一棵树掩盖了标志的一部分时，就难以成功了。还有一个原因，计算机视觉和图像检测还不能与人类相媲美，它太脆弱，太容易受到周围环境的影响。

有关深度学习：

现在深度学习在机器学习领域是一个很热的概念，不过经过各种媒体的转载播报，这个概念也逐渐变得有些神话的感觉：例如，人们可能认为，深度学习是一种能够模拟出人脑的神经结构的机器学习方式，从而能够让计算机具有人一样的智慧；而这样一种技术在将来无疑是前景无限的。那么深度学习本质上又是一种什么样的技术呢？ 深度学习是机器学习领域中对模式（声音、图像等等）进行建模的一种方法，它也是一种基于统计的概率模型。在对各种模式进行建模之后，便可以对各种模式进行识别了，例如待建模的模式是声音的话，那么这种识别便可以理解为语音识别。而类比来理解，如果说将机器学习算法类比为排序算法，那么深度学习算法便是众多 排序算法当中的一种（例如冒泡排序），这种算法在某些应用场景中，会具有一定的优势。

1.过去十年中，神经网络，一种类似哺乳动物大脑突触连接关系的机器学习结构，得以复兴。神经网络不需要人为提取特征。原始数据进入学习算法之后不需要任何的人为工作，我们把它称之为“深度学习”。

2.尽管深度学习技术和学习模型已经存在了几十年了，但是我们现在才看到其理论创新和基于经验的突破，因为基础架构和数据的实用性才刚刚成熟。2006年，NVIDIA推出基于GPU的CUDA开发平台，成为了深度学习发展历史上的风水岭。

3.正是由于深度学习脱离了人为构建特征使其得以成为一种自然的学习工具。很多技能，早在有能力以复杂的数学方式提取特征之前，我们就已经学会了。 这些技能是我们自然而然学会的，难以用高度的特征归纳。通过传统的机器学习手段，是很难凭人类的直觉得出，或是构造出高维的精确特征的。

4.早在我们有能力构建复杂的语义（semantic）之前，我们就已经在机器视觉和自然语言处理等方面取得了很好的成绩。但是学会这些技能不需要我们有数学推理的能力，更不要说人为有意构建的高层语义了。

5.深度学习在广义的高维机器学习问题上已经展现了突破性的成果。其中覆盖的领域包括基因组学 机器学习已经在计算机科学领域存在了很长时间，其关注的重点是创造能够从数据中进行学习的算法，从而让我们可以解决不能直接通过人工编程解决的问题，比如面部识别。其中的基本思想是：我们不直接编写识别人脸的算法，而是编写能够间接地根据样本学习识别人脸的算法。这样的算法可以根据这些样本学习出一个能够量化是否构成一张脸的特征的算法。因为这样的系统基于样本进行学习，所以我们可以以一种连续的方式送入样本，从而使该算法可以连续地更新其内部模型。这将确保我们总是能够识别出面部，即使面部毛发的流行趋势发生了改变。

机器学习的定义是非常宽泛的，即：能够从数据中学习并因此常被应用在语境中的算法。其中一些应用领域包括计算机视觉、语音识别和自然语言处理。机器学习常常和大数据系统联合在一起使用。 前面补充的关于人工智能的知识为下面介绍以哲学的角度探讨人工智能作出铺垫。前面我们反复提到的不管是人工智能，还是机器学习 深度学习都离不开一个词---数据。﻿

图片发自简书App
﻿

21世纪是大数据时代，生活的细枝末节都被数据化，最终形成机器可以识别的机器语言。那么人们常常担心的人工智能的发展是否会对人类的进化，人类文明产生冲击呢？ 答案是必然的，也是不可避免的。人类进化这数百万年来，每一个新事物的产生，尤其是影响人类生活的事物，都必然会改变人类的生活习惯。是否会奇怪为什么淘宝，百度会推送一些你恰好想看或者恰好想买的东西呢？这正是通过你经常浏览的网页，视频，通过算法数据分析，来判断你当前所需。这是不是很可怕呢！﻿﻿

图片发自简书App
﻿

曾有研究团队作出一个关于大数据的调查：通过分析一个人的生活中的相应数据，分析得到这个人的一些隐秘信息，甚至是你的姓名，年龄，且成功率在百分九十以上。细思极恐，但是存在的即是自然合理的。那么人工智能的发展是否可以替代人类呢？ 答案是否定的。人工智能，深度学习的根本还是在于大数据，以前我们往往强调的是数据的准确，甚至是苛刻。

但21世纪的现在，面对大容量的数据，高质量的数据似乎并没有那么重要。相反数以兆记的数据才是人们重视的对象。人类是产生数据的主体，而人工智能是利用数据进行学习，这其中的因果关系不也就证明了人类与人工智能的存在性吗？ 我们可以想一下，AlphaGo赢了李世石因为什么，严格上来说并不是AlphGo赢了李世石而是全球数百万的围棋爱好者，棋谱共同的智慧打败了李世石。这点恐怕是大多人没有想到的，对于不了解人工智能的人来说 ，常常会随口说出这个高大上的词，即使是现在最尖端的人工智能也不能称的上人工智能，我们尚处在弱人工智能时代。

人工智能像是一个人，如今尚处在儿童时期，只能完成人类儿童的一些简单动作。人类比机器的高明之处在于思考，人工智能的发展在于基于大数据去学习。那么人工智能究竟会不会对人类的发展有害呢？ 人工智能的出现像武器一样，人工智能发展并不可怕， 只是怕人工智能技术落入一些别有用心的人手里才是可怕的。人工智能的发展也必然会掀起一场关于劳动力的动荡，可这需要时间 也许像人类的进化一样，需要上百年才能有所进步，技术的发展永远不是绝对的对错，对与错的区别在于使用者，控制的对象。﻿

图片发自简书App
﻿

关于人工智能公共政策的前景与建议。人工智能应用的目标必须是对社会有价值。我们的政策建议也会遵循这个目标，根据斯坦福大学一项关于人工智能百年研究的报告，即便这个报告主要关注的是2030年的北美城市，建议依然广泛适用于其他城市，同时不受时间限制。一些提升解读和人工智能系统能力并参与其使用的策略可以帮助建立信任，同时防止重大失败。 　　

在增强和提升人类能力和互动时需要小心，还有避免对不同社会阶层的歧视。要强调多做鼓励这个方向以及沟通公共政策探讨的研究。报告鉴于美国目前的产业监管，需要新的或重组的法律和政策来应对人工智能可能带来的广泛影响。

政策不需要更多也不要更严，而是应该鼓励有用的创新，生成并转化专业知识，并广泛促进企业与公民对解决这些技术带来的关键社会问题的责任感。长期来看，人工智能将会带来新财富，整个社会也要探讨如何分配人工智能技术带来的经济成果的分配问题。 　　

为了帮助解决个人和社会对快速发展的人工智能技术产生的忧虑，该研究小组提供了三个一般性政策建议。 　

1.在所有层级的政府内，制定一个积累人工智能技术专业知识的程序。有效的监管需要更多的能理解并能分析人工智能技术、程序目标以及整体社会价值之间互动的专家。 　　

缺少足够的安全或其他指标方面的专业技术知识，国家或地方政府官员或许或拒绝批准一个非常有前途的应用。或者缺少足够训练的政府官员可能只会简单采纳行业技术专家的说法，批准一个未经充分审查的敏感的应用进入市场。不理解人工智能系统如何与人工行为和社会价值互动，官员们会从错误的角度来评估人工智能对项目目标的影响。 　　

2.为研究人工智能的平等、安全、隐私和对社会的影响扫清感知到的和实际的障碍。 　　

在一些相关的联邦法律中，如计算机欺诈和滥用法案和数字千年版权法的反规，涉及专有的人工智能系统可能被如何逆向向工程以及被学者、记者和其他研究人员评价的内容还很模糊。当人工智能系统带来了一些实质性后果需要被审查和追究责任时，这些法律的研究就非常重要了。 　　

3.为人工智能社会影响的跨学科研究提供公共和私人资金支持。 　　

从整个社会来看，我们对人工智能技术的社会影响的研究投入不足。资金要投给那些能够从多角度分析人工智能的跨学科团队，研究范围从智能的基础研究到评估安全、隐私和其他人工智能影响的方法。

以下是一些具体问题： 　　

当一辆自动驾驶汽车或智能医疗设备出现失误时，应该由谁来负责？如何防止人工智能应用产生非法歧视？谁来享有人工智能技术带来的效率提升的成果，以及对于那些技能被淘汰的人应该采取什么样的保护？ 　　

随着人工智能被越来越广泛和深入地整合到工业和消费产品中，一些领域中需要调整现有的建立监管制度以适应人工智能创新，或者在某些情况下，根据广泛接受的目标和原则，从根本上重新配置监管制度。 　　

在美国，已经通过各种机构将监管具体到各个行业。在设备中使用人工智能实现医疗诊断和治疗由食品药品监督管理局监管，包括定义产品类型和指定产生方法，还有软件工程的标准。无人机在管制空域中的使用由美国联邦航空局监管。面向消费者的人工智能系统将由联邦贸易委员会监管。金融市场使用的人工智能技术，如高频交易，由证券交易委员会监管。 　　

除了针对具体行业制定监管的方法外，「重要基础设施」中定义模糊和广泛的监管类别可能适用于人工智能应用。鉴于目前美国行政法结构，短期内制定出全面的人工智能政策法规似乎不太可能。但是，可以根据人工智能在各种情境中可能出现的法律和政策问题，广泛列出多个类别。

隐私 　　

创新政策 　　

责任（民事） 　　

责任（刑事） 　　

代理 　　

认证 　　

劳动力 　　

税务 　　

政治 　　

未来的指导原则 　　

面对人工智能技术将带来的深刻变化，要求更全面具体的监管的压力是不可避免的。对人工智能是什么和不是什么的误解（尤其在这个恐慌易于散布的背景下）可能引发对有益于所有人的技术的反对。那将会是一个悲剧性的错误。扼杀创新或将创新转移到它处的监管方法同样也只会适得其反。 　　

幸运的是，引导当前数字技术的成功监管原则可以给我们带来指导。比如，一项最近公布的多年研究对比了欧洲四个国家和美国的隐私监管，其结果却很反直觉。其影响是抑制创新和强大的隐私保护。 　　

这些公司并不将隐私保护看作是内部责任，也不会拿出专门的员工来促进其业务或制造流程中的隐私保护，也不会参与必需范围之外的隐私倡议或学术研究；这些公司只是将隐私看作是一项要满足规范的行为。他们关注的重点是避免罚款或惩罚，而非主动设计技术和采纳实际技术来保护隐私。 　　

相对地，美国和德国的监管环境是模糊的目标和强硬的透明度要求和有意义的执法的结合，从而在促进公司将隐私看作是他们的责任上做得更加成功。广泛的法律授权鼓励企业发展执行隐私控制的专业人员和流程、参与到外部的利益相关者中并采用他们的做法以实现技术进步。对更大的透明度的要求使民间社会团队和媒体可以变成法庭上和法庭外的公共舆论中的可靠执法者，从而使得隐私问题在公司董事会上更加突出，这又能让他们进一步投资隐私保护。 　　

在人工智能领域也是一样，监管者可以强化涉及内部和外部责任、透明度和专业化的良性循环，而不是定义狭窄的法规。随着人工智能与城市的整合，它将继续挑战对隐私和责任等价值的已有保护。和其它技术一样，人工智能也可以被用于好的或恶意的目的。 　　

这份报告试图同时强调这两方面的可能性。我们急切地需要一场重要的辩论：如何最好地引导人工智能以使之丰富我们的生活和社会，同时还能鼓励这一领域的创新。应该对政策进行评估，看其是否能促进人工智能所带来的益处的发展和平等共享，还是说会将力量和财富集中到少数权贵的手里。而因为我们并不能完美清晰地预测未来的人工智能技术及其所将带来的影响，所以相关政策一定要根据出现的社会难题和线索不断地重新评估。 　　

截至本报告发布时，重要的人工智能相关的进展已经在过去十五年内给北美的城市造成了影响，而未来十五年还将有更大幅度的发展发生。最近的进展很大程度是由于互联网所带来的大型数据集的增长和分析、传感技术的进步和最近的「深度学习」的应用。 　　

未来几年，随着公众在交通和医疗等领域内与人工智能应用的遭遇，它们必须以一种能构建信任和理解的方式引入，同时还要尊重人权和公民权利。在鼓励创新的同时，政策和流程也应该解决得到、隐私和安全方面的影响，而且应该确保人工智能所带来的好处能得到广泛而公正的分配。如果人工智能研究及其应用将会给2030年及以后的北美城市生活带来积极的影响，那么这样做就是非常关键的。
﻿

图片发自简书App

﻿关于人工智能人类最大的担忧是机器人会不会杀死人类？ 答案是否定的。 在谈论人工智能（AI）及其对人类未来的影响时，曾在互联网上引发有关“裙子颜色”类似的争论。有些人看到AI存在的巨大潜力，而其他人担心AI对人类产生威胁，比如超级智能机器可能将人类当成宠物，人工智能机器人甚至可能终结整个人类。

美国斯坦福大学推出“人工智能100年发展研究计划”，以对AI的未来进行长期评估。这个计划的目标是设立由科学家组成的常设委员会，定期公布AI报告，以广阔的目光审视AI触及人类日常生活的方方面面。现在，他们正收集流行文化中有关AI的描述、科技思想家的警告、有关我们智能手机和其他设备中AI助理的炒作。

斯坦福大学日前公布了首份报告，即2.8万字的《AI与2030年生活》。这份报告历时1年多完成，主要探讨AI进步对北美典型城市未来10年的影响。 《AI与2030年生活》报告作者之一、美国德克萨斯大学计算机科学家彼得·斯通说：“电影和文学作品中对AI的描述都是虚构的，包含了许多人们对AI的误解。我们发现，人们对AI的态度处于两级分化状态：有些人对AI充满渴望，为其取得进步雀跃不已，甚至达到令人不可思议的痴迷程度。而其他人则对其感到恐惧，认为AI将会毁掉人类，这同样是不现实的。”

在分析部分，斯通与同事们研究了人类未来城市生活的几个方面。他们认为，将来AI很可能会颠覆这些领域的当前现状。研究人员认为，将来AI将无所不在，并将发挥重要影响力。从交通、医疗、教育以及就业等方面看，研究显示AI的功能有点儿像现在的智能手机。这并非是说它们取代了你的生活，而是大多数人没有它们可能会觉得很不方便。
﻿

图片发自简书App

﻿报告中称，交通很可能是AI应用的首个重要领域，公众要求可靠、安全的AI系统执行关键任务。自动化交通很快将无所不在，而当大多数人都亲身体验过AI系统后，这将强烈影响人们对AI的认知。研究人员认为，当前的医疗保健系统在结构上不合理，无法支持快速部署高科技的AI。

但是在未来15年，将由足够多的先进AI系统、充足的数据以及有针对性的系统，帮助医生分担计算型任务。 此外，AI还能更快地从人口数据中提取深刻洞见，令更个性化的诊断和治疗成为可能。展望未来，医疗领域的许多任务似乎都可通过AI加强，但可能不会实现全自动化。举例来说，机器人将可为医院病房递送药品，但是它们需要人类帮忙分配，并将药物放在最终位置上。 治安与公共安全是AI应用的另一个领域，尽管其更为复杂。AI可以帮助警务变得更有针对性。随着AI在图像质量和面部识别等方面的改善，摄像头将可以更好滴帮助预防犯罪和起诉罪犯。此外，AI还可帮助执法机构进行社交网络分析等。报告中称：“执法机构对从社交媒体上发现破坏性计划越来越感兴趣，同时也可通过社交媒体监控大型集会以分析安全性。对群体行为进行模拟分析非常重要，可确定如何控制此类事件。与此同时，人们对执法机构过度使用此类工具侵犯个人隐私也更加担忧。” 当涉及就业和职场时，研究认为AI可取代任务而非工作岗位，同时可帮助创造新的工作。报告作者们称，他们没有发现任何担心AI的理由，AI不会对人类产生迫在眉睫的威胁。

《AI与2030年生活》报告发布时，其他机构和公司也在为AI研究提供资源支持，并关注顶级科学家关于AI对人类未来影响的研究。剑桥大学设立了新的研究中心，专门研究AI。斯坦福大学报告发布后数周，亚马逊、IBM、微软、谷歌以及Facebook五家公司联合宣布，组建名为人工智能造福人类和社会合作组织的非营利机构。 白宫也曾于10月份发布AI白皮书，认为政府需要在AI研究中发挥重要作用。这也是斯坦福大学《AI与2030年生活》报告中得出的重要结论。

斯通说：“我们建议各级政府都需要有AI专长的人，当出现与AI有关的决策时，这样的人就可以发挥重要作用，帮助最大程度做出正确决定。” 当被问及我们是否应该担心AI变得足够聪明，将来可能毁掉人类时，斯通给出否定回答。他说：“即使我们拥有能够自动驾驶的汽车，也并非意味着我们拥有可为你叠衣或做其他事情的机器人。要想实现这些功能，需要持续的研究努力，而它们并不容易解决。任何技术都有优势和潜在负面影响，关键是看它被谁和如何被使用。总的来说，我对AI的未来感到非常乐观，它们将帮助改善世界。